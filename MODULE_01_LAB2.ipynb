{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODedqNjV0tJMbBnmCWb0V8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saisumedha/FMML-PROJECTS_AND_LABS/blob/main/MODULE_01_LAB2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kJ10oIFJ1a8l"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "# set randomseed\n",
        "rng = np.random.default_rng(seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset =  datasets.fetch_california_housing()\n",
        ""
      ],
      "metadata": {
        "id": "ufG1EoOU183x"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.DESCR)\n",
        "print(dataset.keys())\n",
        "dataset.target = dataset.target.astype(int)\n",
        "print(dataset.data.shape)\n",
        "print(dataset.target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gp25N442z6e",
        "outputId": "ba855312-4c1a-4911-abab-7bb9505bdc73"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _california_housing_dataset:\n",
            "\n",
            "California Housing dataset\n",
            "--------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 20640\n",
            "\n",
            "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
            "\n",
            "    :Attribute Information:\n",
            "        - MedInc        median income in block group\n",
            "        - HouseAge      median house age in block group\n",
            "        - AveRooms      average number of rooms per household\n",
            "        - AveBedrms     average number of bedrooms per household\n",
            "        - Population    block group population\n",
            "        - AveOccup      average number of household members\n",
            "        - Latitude      block group latitude\n",
            "        - Longitude     block group longitude\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "This dataset was obtained from the StatLib repository.\n",
            "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
            "\n",
            "The target variable is the median house value for California districts,\n",
            "expressed in hundreds of thousands of dollars ($100,000).\n",
            "\n",
            "This dataset was derived from the 1990 U.S. census, using one row per census\n",
            "block group. A block group is the smallest geographical unit for which the U.S.\n",
            "Census Bureau publishes sample data (a block group typically has a population\n",
            "of 600 to 3,000 people).\n",
            "\n",
            "A household is a group of people residing within a home. Since the average\n",
            "number of rooms and bedrooms in this dataset are provided per household, these\n",
            "columns may take surprisingly large values for block groups with few households\n",
            "and many empty houses, such as vacation resorts.\n",
            "\n",
            "It can be downloaded/loaded using the\n",
            ":func:`sklearn.datasets.fetch_california_housing` function.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
            "      Statistics and Probability Letters, 33 (1997) 291-297\n",
            "\n",
            "dict_keys(['data', 'target', 'frame', 'target_names', 'feature_names', 'DESCR'])\n",
            "(20640, 8)\n",
            "(20640,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def NN1(traindata, trainlabel, query):\n",
        "  diff  = traindata - query  # find the difference between features. Numpy automatically takes care of the size here\n",
        "  sq = diff*diff # square the differences\n",
        "  dist = sq.sum(1) # add up the squares\n",
        "  label = trainlabel[np.argmin(dist)] # our predicted label is the label of the training data which has the least distance from the query\n",
        "  return label\n",
        "\n",
        "def NN(traindata, trainlabel, testdata):\n",
        "  # we will run nearest neighbour for each sample in the test data\n",
        "  # and collect the predicted classes in an array using list comprehension\n",
        "  predlabel = np.array([NN1(traindata, trainlabel, i) for i in testdata])\n",
        "  return predlabel"
      ],
      "metadata": {
        "id": "iAGlEPkv3JsW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RandomClassifier(traindata, trainlabel, testdata):\n",
        "  # in reality, we don't need these arguments\n",
        "\n",
        "  classes = np.unique(trainlabel)\n",
        "  rints = rng.integers(low=0, high=len(classes), size=len(testdata))\n",
        "  predlabel = classes[rints]\n",
        "  return predlabel"
      ],
      "metadata": {
        "id": "iwkrvG0c3R89"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Accuracy(gtlabel, predlabel):\n",
        "  assert len(gtlabel)==len(predlabel), \"Length of the groundtruth labels and predicted labels should be the same\"\n",
        "  correct = (gtlabel==predlabel).sum() # count the number of times the groundtruth label is equal to the predicted label.\n",
        "  return correct/len(gtlabel)"
      ],
      "metadata": {
        "id": "KLPEO3PK355O"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split(data, label, percent):\n",
        "  # generate a random number for each sample\n",
        "  rnd = rng.random(len(label))\n",
        "  split1 = rnd<percent\n",
        "  split2 = rnd>=percent\n",
        "  split1data = data[split1,:]\n",
        "  split1label = label[split1]\n",
        "  split2data = data[split2,:]\n",
        "  split2label = label[split2]\n",
        "  return split1data, split1label, split2data, split2label"
      ],
      "metadata": {
        "id": "S-l6JieJ3_dw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdata, testlabel, alltraindata, alltrainlabel = split(dataset.data, dataset.target, 20/100)\n",
        "print('Number of test samples = ', len(testlabel))\n",
        "print('Number of other samples = ', len(alltrainlabel))\n",
        "print('Percent of test data = ', len(testlabel)*100/len(dataset.target),'%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmyGphzJ4weL",
        "outputId": "5dcde999-0b54-4ab2-caf5-500bfa61aedc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test samples =  4144\n",
            "Number of other samples =  16496\n",
            "Percent of test data =  20.07751937984496 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata, trainlabel, valdata, vallabel = split(alltraindata, alltrainlabel, 75/100)"
      ],
      "metadata": {
        "id": "ruxKEM4G41mz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainpred = NN(traindata, trainlabel, traindata)\n",
        "trainAccuracy = Accuracy(trainlabel, trainpred)\n",
        "print(\"Train accuracy using nearest neighbour is \", trainAccuracy)\n",
        "\n",
        "trainpred = RandomClassifier(traindata, trainlabel, traindata)\n",
        "trainAccuracy = Accuracy(trainlabel, trainpred)\n",
        "print(\"Train accuracy using random classifier is \", trainAccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHtyS41K47sx",
        "outputId": "425e5d9b-c634-4a41-987f-af55a9823a39"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy using nearest neighbour is  1.0\n",
            "Train accuracy using random classifier is  0.164375808538163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valpred = NN(traindata, trainlabel, valdata)\n",
        "valAccuracy = Accuracy(vallabel, valpred)\n",
        "print(\"Validation accuracy using nearest neighbour is \", valAccuracy)\n",
        "\n",
        "valpred = RandomClassifier(traindata, trainlabel, valdata)\n",
        "valAccuracy = Accuracy(vallabel, valpred)\n",
        "print(\"Validation accuracy using random classifier is \", valAccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnvDNgh25JHT",
        "outputId": "07acf4b8-cb3a-435c-8d0a-e9c37b30f3e1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy using nearest neighbour is  0.34108527131782945\n",
            "Validation accuracy using random classifier is  0.1688468992248062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata, trainlabel, valdata, vallabel = split(alltraindata, alltrainlabel, 75/100)\n",
        "valpred = NN(traindata, trainlabel, valdata)\n",
        "valAccuracy = Accuracy(vallabel, valpred)\n",
        "print(\"Validation accuracy of nearest neighbour is \", valAccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ateh9cOP5Jdg",
        "outputId": "48c06b4d-3a62-4cef-8f45-20dfc9140a94"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy of nearest neighbour is  0.34048257372654156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testpred = NN(alltraindata, alltrainlabel, testdata)\n",
        "testAccuracy = Accuracy(testlabel, testpred)\n",
        "print('Test accuracy is ', testAccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwNNTVR_5Sfb",
        "outputId": "19034078-fe5e-4052-9761-e5b4b8847a10"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy is  0.34917953667953666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1)When we increase the percentage of data reserved for the validation set, we have less data available for training.\n",
        "A larger validation set can provide a better estimate of our model's performance on unseen data, making it more reliable for hyperparameter tuning and model selection.\n",
        "With a smaller training set, our model may not learn as effectively, and it might suffer from underfitting. This could result in lower training accuracy, and the model may not generalize well to the test data.\n",
        "Reducing the size of the validation set means we have more data available for training.\n",
        "A larger training set can help our model learn more effectively, potentially improving its accuracy on the training data.\n",
        "A smaller validation set might not provide a robust estimate of your model's generalization performance, which can lead to overfitting. Overfit models may perform well on the training data but poorly on the test data."
      ],
      "metadata": {
        "id": "4uoKxgslBDcF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2)If the training set is too small, the model might not learn important patterns, and the validation set may not be able to accurately predict test set performance.\n",
        "If the validation set is too small, it might not provide a reliable estimate of test accuracy."
      ],
      "metadata": {
        "id": "5FWlE5EvB_y_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3)It should be large enough to provide a meaningful estimate of our model's performance but not so large that it hampers our model's ability to learn.\n",
        "A common split is 70-80% for training and 20-30% for validation."
      ],
      "metadata": {
        "id": "r23A0Eo9CWSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# you can use this function for random classifier also\n",
        "def AverageAccuracy(alldata, alllabel, splitpercent, iterations, classifier=NN):\n",
        "  accuracy = 0\n",
        "  for ii in range(iterations):\n",
        "    traindata, trainlabel, valdata, vallabel = split(alldata, alllabel, splitpercent)\n",
        "    valpred = classifier(traindata, trainlabel, valdata)\n",
        "    accuracy += Accuracy(vallabel, valpred)\n",
        "  return accuracy/iterations # average of all accuracies"
      ],
      "metadata": {
        "id": "msSxVFfEAPRR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Average validation accuracy is ', AverageAccuracy(alltraindata, alltrainlabel, 75/100, 10, classifier=NN))\n",
        "testpred = NN(alltraindata, alltrainlabel, testdata)\n",
        "print('test accuracy is ',Accuracy(testlabel, testpred) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUfWRzJuATww",
        "outputId": "7940088e-35e7-48eb-c0df-c77f0f89ebde"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average validation accuracy is  0.33584635395170215\n",
            "test accuracy is  0.34917953667953666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Averaging validation accuracy across multiple splits can provide more consistent and reliable results compared to a single train-validation\n",
        "When we perform multiple splits and calculate validation accuracy for each split, we understand about how our model performs on different subsets of the data. This helps to reduce the impact of data randomness or bias that can occur in a single split.\n",
        "Averaging the results smoothes out the variations in performance that might arise due to the random selection of the validation set. This leads to more stable and consistent estimates.\n",
        "\n",
        "By averaging results from multiple splits, we get more robust estimate of how well our model generalizes to unseen data. This estimate tends to be more accurate because it's based on a broader range of data samples.It helps reduce the risk of overfitting to a specific validation set, which can happen when using a single fixed validation set.\n",
        "\n",
        "The number of iterations can impact the estimate's accuracy and stability.Increasing the number of iterations leads to a more accurate estimate but also requires more computational resources.The optimal number of iterations can vary depending on our dataset size and characteristics.if our dataset is extremely small, increasing the number of iterations alone may not be a complete solution. we might still face challenges related to the limited amount of data available for training and validation.\n",
        "\n",
        " averaging validation accuracy across multiple splits through cross-validation provides more consistent and accurate estimates of test accuracy. While increasing the number of iterations can improve the estimate's quality, it's not a substitute for having a sufficiently large and diverse dataset, especially if our dataset is exceptionally small. A balanced approach, considering both dataset size and cross-validation, is often the best strategy for model evaluation.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FtfcLTfYCsNv"
      }
    }
  ]
}